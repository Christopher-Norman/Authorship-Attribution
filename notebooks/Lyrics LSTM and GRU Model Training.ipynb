{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Lyrics LSTM and GRU Model Training.ipynb","provenance":[],"authorship_tag":"ABX9TyNQGpleWT9Zgg6xtC2VRaix"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4q5C2cA-EmrB","executionInfo":{"status":"ok","timestamp":1652006318555,"user_tz":-60,"elapsed":6542,"user":{"displayName":"Harvey South","userId":"00286034947533783714"}},"outputId":"eec936af-1634-4f6c-ede5-748611e566c6"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}],"source":["from google.colab import drive\n","#specify project directory in drive eg /content/drive/NLUProject\n","# drive.flush_and_unmount()\n","drive.mount('/content/drive')\n","\n","#define necessary imports\n","import time\n","import torch\n","import torch.nn as nn\n","import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","import nltk\n","\n","from torch.utils.data import Dataset, DataLoader\n","\n","import gensim"]},{"cell_type":"code","source":["class lyricDataset(Dataset):\n","    \"\"\"lyric dataset.\"\"\"\n","\n","    def __init__(self, df):\n","        self.df = df\n","        self.maxLenForDF = self.getMaximumLengthSequence()\n","        self.padReturningItems(self.maxLenForDF)\n","        self.sendListToTensors()\n","\n","    def padReturningItems(self, lengthToPadTo):\n","        for index, row in self.df.iterrows():\n","            # if(index % 100 == 0):\n","            #   print(index)\n","            paddingNeeded = (lengthToPadTo - len(row['lyric_tokens_reduced']))\n","            if(paddingNeeded > 0):\n","                padData = [paddingID] * paddingNeeded\n","                self.df.at[index, 'lyric_tokens_reduced'] = row['lyric_tokens_reduced'] + padData\n","\n","    def sendListToTensors(self):\n","        for index, row in self.df.iterrows():\n","            self.df.at[index, \"lyric_tokens_reduced\"] = torch.tensor(row['lyric_tokens_reduced'], dtype=torch.int)\n","            self.df.at[index, \"artist_label\"] = torch.tensor(row['artist_label'], dtype=torch.int)\n","\n","    def __len__(self):\n","        return self.df.shape[0]\n","\n","    def getMaximumLengthSequence(self):\n","        #print(df)\n","        dfColumnAsList = self.df['lyric_tokens_reduced'].tolist()\n","        listOfListLengths = [len(i) for i in dfColumnAsList]\n","        return max(listOfListLengths)\n","\n","    def __getitem__(self, idx):\n","        if torch.is_tensor(idx):\n","            idx = idx.tolist()\n","        dfRowToReturn = self.df.iloc[idx]\n","        dictToReturn = {'input': dfRowToReturn['lyric_tokens_reduced'], 'label': dfRowToReturn['artist_label']}\n","        #print(dictToReturn)\n","        return dictToReturn\n","#get the number of unique authors\n","    def getAuthorCount(self):\n","        uniqueAuthors = self.df[\"artist_label\"].unique()\n","        uniqueAuthorLength = len(uniqueAuthors)\n","        return uniqueAuthorLength"],"metadata":{"id":"SiTw7ZgAItgG","executionInfo":{"status":"ok","timestamp":1652006318555,"user_tz":-60,"elapsed":4,"user":{"displayName":"Harvey South","userId":"00286034947533783714"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["#load datasets back in\n","train_dataset = torch.load('drive/MyDrive/NLU Project/data/PyTorchDataset/LyricTrain.pt')\n","validate_dataset = torch.load('drive/MyDrive/NLU Project/data/PyTorchDataset/LyricValidate.pt')\n","test_dataset = torch.load('drive/MyDrive/NLU Project/data/PyTorchDataset/LyricTest.pt')"],"metadata":{"id":"wEOX_HIEIEdF","executionInfo":{"status":"ok","timestamp":1652006388615,"user_tz":-60,"elapsed":70064,"user":{"displayName":"Harvey South","userId":"00286034947533783714"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["#define special tokens\n","unknownToken = \"<unk>\"\n","padToken = \"<pad>\"\n","#Load gensim model in\n","model = gensim.models.KeyedVectors.load('drive/MyDrive/NLU Project/data/preProcessedEmbeddings/lyric-glove_vectors.kv')\n","paddingID = model.vocab[padToken].index"],"metadata":{"id":"XtlprszzJL5L","executionInfo":{"status":"ok","timestamp":1652006391371,"user_tz":-60,"elapsed":2760,"user":{"displayName":"Harvey South","userId":"00286034947533783714"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["batchSize = 64\n","train_dataloader = DataLoader(train_dataset, batch_size=batchSize, shuffle=True)\n","test_dataloader = DataLoader(test_dataset, batch_size=batchSize)"],"metadata":{"id":"8ju-CgXrIDRU","executionInfo":{"status":"ok","timestamp":1652006391372,"user_tz":-60,"elapsed":10,"user":{"displayName":"Harvey South","userId":"00286034947533783714"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["#define LSTM model\n","class LSTMModel(torch.nn.Module):\n","\n","  def __init__(self, pretrainedEmbeddingWeights, lstmHiddenDimensions, lstmLayerNumber, outputClassNumber, paddingId):\n","    super(LSTMModel, self).__init__()\n","    self.EmbeddingLayer = nn.Embedding.from_pretrained(pretrainedEmbeddingWeights, padding_idx = paddingId)\n","    self.EmbeddingDimensions = pretrainedEmbeddingWeights.size()[1]\n","    self.LSTMLayer = nn.LSTM(self.EmbeddingDimensions, lstmHiddenDimensions, batch_first=True)\n","    self.LinearLayer = nn.Linear(lstmHiddenDimensions, outputClassNumber)\n","    self.nnSoftMax = nn.LogSoftmax()\n","\n","  def forward(self, input):\n","    embeddedInput = self.EmbeddingLayer(input)\n","    lstmOutput, (finalHiddenStates, finalCellStates) = self.LSTMLayer(embeddedInput)\n","\n","    lstmOutsPooled = torch.mean(lstmOutput, dim=1)\n","    linearOutput = self.LinearLayer(lstmOutsPooled)\n","    softMaxOut = self.nnSoftMax(linearOutput)\n","\n","    return softMaxOut\n","# Define GRU model\n","class GRUModel(torch.nn.Module):\n","\n","  def __init__(self, pretrainedEmbeddingWeights, gruHiddenDimensions, gruLayerNumber, outputClassNumber, paddingId):\n","    super(GRUModel, self).__init__()\n","    self.EmbeddingLayer = nn.Embedding.from_pretrained(pretrainedEmbeddingWeights, padding_idx = paddingId)\n","    self.EmbeddingDimensions = pretrainedEmbeddingWeights.size()[1]\n","    self.GRULayer = nn.GRU(self.EmbeddingDimensions, gruHiddenDimensions, batch_first=True)\n","    self.LinearLayer = nn.Linear(gruHiddenDimensions, outputClassNumber)\n","    self.nnSoftMax = nn.LogSoftmax()\n","\n","  def forward(self, input):\n","    embeddedInput = self.EmbeddingLayer(input)\n","    gruOutput, finalHiddenStates = self.GRULayer(embeddedInput)\n","    gruOutsPooled = torch.mean(gruOutput, dim=1)\n","    linearOutput = self.LinearLayer(gruOutsPooled)\n","\n","    softMaxOut = self.nnSoftMax(linearOutput)\n","    # print(softMaxOut.size())\n","    return softMaxOut\n"],"metadata":{"id":"QMv0lsAjIIIB","executionInfo":{"status":"ok","timestamp":1652006391372,"user_tz":-60,"elapsed":9,"user":{"displayName":"Harvey South","userId":"00286034947533783714"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":["#define function to check accuracy with a dataloader\n","def get_accuracy(dataloader, model):\n","\n","  model.eval()\n","  correctlyPredictedNum = 0\n","  acummulateLength = 0\n","\n","  for i, data in enumerate(dataloader):\n","\n","    modelOutputOnSampleBatch = model(data['input'])\n","    classPredictions = np.argmax(modelOutputOnSampleBatch.detach().numpy(), axis=1)\n","    correctBoolean = classPredictions == data['label'].detach().numpy()\n","    correctlyPredictedNum += np.sum(correctBoolean)\n","\n","    acummulateLength+= data['input'].size(0)\n","\n","  accuracyToReturn = correctlyPredictedNum / acummulateLength\n","  model.train()\n","\n","  return accuracyToReturn"],"metadata":{"id":"nhuDeCVlIMKw","executionInfo":{"status":"ok","timestamp":1652006391372,"user_tz":-60,"elapsed":9,"user":{"displayName":"Harvey South","userId":"00286034947533783714"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","source":["#Define model hyperparameters\n","outputSize = train_dataset.getAuthorCount()\n","hiddnSize = 64\n","layers = 3"],"metadata":{"id":"IaZiZp50I_a9","executionInfo":{"status":"ok","timestamp":1652006391373,"user_tz":-60,"elapsed":10,"user":{"displayName":"Harvey South","userId":"00286034947533783714"}}},"execution_count":9,"outputs":[]},{"cell_type":"code","source":["outputSize = 14691\n","preTrainedEmbeddings = torch.from_numpy(model.vectors)"],"metadata":{"id":"iUDm3f3qLPDd","executionInfo":{"status":"ok","timestamp":1652006405980,"user_tz":-60,"elapsed":214,"user":{"displayName":"Harvey South","userId":"00286034947533783714"}}},"execution_count":13,"outputs":[]},{"cell_type":"code","source":["#train the LSTM model\n","\n","\n","LSTMTrainedModel = LSTMModel(preTrainedEmbeddings, hiddnSize, layers, outputSize, paddingID)\n","LSTMTrainedModel.float()\n","lossFunction = nn.NLLLoss()\n","optimizer = torch.optim.Adam(LSTMTrainedModel.parameters(), lr=0.001)\n","\n","epochTestAccuracyListLSTM = []\n","epochTrainAccuracyListLSTM = []\n","\n","lossForBatch = 0\n","import time\n","timeStart = time.time()\n","for epoch in range(20):\n","  if(time.time() - timeStart > 43200):\n","      break\n","  for i, data in enumerate(train_dataloader):\n","    if(time.time() - timeStart > 43200):\n","      break\n","    LSTMTrainedModel.train()\n","    optimizer.zero_grad()\n","    modelOutputOnSampleBatch = LSTMTrainedModel(data['input'])\n","    lossForBatch = lossFunction(modelOutputOnSampleBatch, data['label'])\n","    lossForBatch.backward()\n","    optimizer.step()\n","    if(i % 100 == 0):\n","      print(\"Step run on batch\", i, \"time:\",(time.time() - timeStart), \"loss:\", lossForBatch)\n","\n","  testAccuracyThisEpochLSTM = get_accuracy(test_dataloader, LSTMTrainedModel)\n","  print(\"Accuracy epoch TESTING\", epoch, \":\", testAccuracyThisEpochLSTM, \"time:\", (time.time() - timeStart))\n","  epochTestAccuracyListLSTM.append(testAccuracyThisEpochLSTM)\n","\n","  trainAccuracyThisEpochLSTM = get_accuracy(train_dataloader, LSTMTrainedModel)\n","  print(\"Accuracy epoch TRAINING\", epoch, \":\", trainAccuracyThisEpochLSTM, \"time:\", (time.time() - timeStart))\n","  epochTrainAccuracyListLSTM.append(trainAccuracyThisEpochLSTM)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":452},"id":"obioqBGMISeB","executionInfo":{"status":"error","timestamp":1652006256353,"user_tz":-60,"elapsed":515342,"user":{"displayName":"Harvey South","userId":"00286034947533783714"}},"outputId":"a65bf02e-c439-455e-ff90-6712639c9f0b"},"execution_count":13,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:18: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n"]},{"output_type":"stream","name":"stdout","text":["Step run on batch 0 time: 1.104745864868164 loss: tensor(9.6015, grad_fn=<NllLossBackward0>)\n","Accuracy epoch TESTING 0 : 0.00096 time: 314.0166404247284\n"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-13-5028afecf151>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     32\u001b[0m   \u001b[0mepochTestAccuracyListLSTM\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtestAccuracyThisEpochLSTM\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m   \u001b[0mtrainAccuracyThisEpochLSTM\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_accuracy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mLSTMTrainedModel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Accuracy epoch TRAINING\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\":\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainAccuracyThisEpochLSTM\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"time:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mtimeStart\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m   \u001b[0mepochTrainAccuracyListLSTM\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainAccuracyThisEpochLSTM\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-7-ef02659465bb>\u001b[0m in \u001b[0;36mget_accuracy\u001b[0;34m(dataloader, model)\u001b[0m\n\u001b[1;32m      8\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mmodelOutputOnSampleBatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'input'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m     \u001b[0mclassPredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodelOutputOnSampleBatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mcorrectBoolean\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclassPredictions\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'label'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1111\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-6-e89248b2f180>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     12\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0membeddedInput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEmbeddingLayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m     \u001b[0mlstmOutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mfinalHiddenStates\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfinalCellStates\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLSTMLayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membeddedInput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0mlstmOutsPooled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlstmOutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1111\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m    760\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbatch_sizes\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    761\u001b[0m             result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n\u001b[0;32m--> 762\u001b[0;31m                               self.dropout, self.training, self.bidirectional, self.batch_first)\n\u001b[0m\u001b[1;32m    763\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    764\u001b[0m             result = _VF.lstm(input, batch_sizes, hx, self._flat_weights, self.bias,\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","source":["# # # COMMENTED To prevent overwrite during testing\n","# #save model weights\n","# torch.save(LSTMTrainedModel.state_dict(), 'drive/MyDrive/NLU Project/data/modelLyricsLSTM')\n","# #save the lists\n","# import pickle\n","# with open('drive/MyDrive/NLU Project/data/LyricsLSTMTestList', 'wb') as f:\n","#   pickle.dump(epochTestAccuracyListLSTM, f)\n","# with open('drive/MyDrive/NLU Project/data/LyricsLSTMTrainList', 'wb') as f:\n","#   pickle.dump(epochTrainAccuracyListLSTM, f)\n","# #run an experiment, optimizing the hyperparameters\n","# import matplotlib.pyplot as plt\n","# epochRange = np.arange(len(epochTrainAccuracyListLSTM))\n","# plt.plot(epochRange, epochTrainAccuracyListLSTM, label = \"Train Accuracy\")\n","# plt.plot(epochRange, epochTestAccuracyListLSTM, label = \"Test Accuracy\")\n","# plt.legend()\n","# plt.show()"],"metadata":{"id":"N9-eA0yTIaBC","executionInfo":{"status":"ok","timestamp":1652006391373,"user_tz":-60,"elapsed":9,"user":{"displayName":"Harvey South","userId":"00286034947533783714"}}},"execution_count":11,"outputs":[]},{"cell_type":"code","source":["#Train for the GRU model\n","\n","GRUTrainedModel = GRUModel(preTrainedEmbeddings, hiddnSize, layers, outputSize, paddingID)\n","GRUTrainedModel.float()\n","lossFunction = nn.NLLLoss()\n","optimizer = torch.optim.Adam(GRUTrainedModel.parameters(), lr=0.001)\n","\n","epochTestAccuracyListGRU = []\n","epochTrainAccuracyListGRU = []\n","\n","lossForBatch = 0\n","import time\n","timeStart = time.time()\n","for epoch in range(20):\n","  if(time.time() - timeStart > 20):\n","      break\n","  for i, data in enumerate(train_dataloader):\n","    if(time.time() - timeStart > 20):\n","      break\n","    GRUTrainedModel.train()\n","    optimizer.zero_grad()\n","    modelOutputOnSampleBatch = GRUTrainedModel(data['input'])\n","    lossForBatch = lossFunction(modelOutputOnSampleBatch, data['label'])\n","    lossForBatch.backward()\n","    optimizer.step()\n","    if(i % 100 == 0):\n","      print(\"Step run on batch\", i, \"time:\",(time.time() - timeStart), \"loss:\", lossForBatch)\n","\n","  testAccuracyThisEpochGRU = get_accuracy(test_dataloader, GRUTrainedModel)\n","  print(\"Accuracy epoch TESTING\", epoch, \":\", testAccuracyThisEpochGRU, \"time:\", (time.time() - timeStart))\n","  epochTestAccuracyListGRU.append(testAccuracyThisEpochGRU)\n","\n","  trainAccuracyThisEpochGRU = get_accuracy(train_dataloader, GRUTrainedModel)\n","  print(\"Accuracy epoch TRAINING\", epoch, \":\", trainAccuracyThisEpochGRU, \"time:\", (time.time() - timeStart))\n","  epochTrainAccuracyListGRU.append(trainAccuracyThisEpochGRU)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":435},"id":"zgi1U5TKIdEj","executionInfo":{"status":"error","timestamp":1652006484174,"user_tz":-60,"elapsed":75220,"user":{"displayName":"Harvey South","userId":"00286034947533783714"}},"outputId":"3d6569dd-756a-4ed2-9ff5-8ce388d032ee"},"execution_count":14,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:38: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n"]},{"output_type":"stream","name":"stdout","text":["Step run on batch 0 time: 0.9917905330657959 loss: tensor(9.6059, grad_fn=<NllLossBackward0>)\n"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-14-eb3d77483f9d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     27\u001b[0m       \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Step run on batch\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"time:\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mtimeStart\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"loss:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlossForBatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m   \u001b[0mtestAccuracyThisEpochGRU\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_accuracy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mGRUTrainedModel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Accuracy epoch TESTING\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\":\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtestAccuracyThisEpochGRU\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"time:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mtimeStart\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m   \u001b[0mepochTestAccuracyListGRU\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtestAccuracyThisEpochGRU\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-8-ef02659465bb>\u001b[0m in \u001b[0;36mget_accuracy\u001b[0;34m(dataloader, model)\u001b[0m\n\u001b[1;32m      8\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mmodelOutputOnSampleBatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'input'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m     \u001b[0mclassPredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodelOutputOnSampleBatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mcorrectBoolean\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclassPredictions\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'label'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1111\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-7-e89248b2f180>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     32\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m     \u001b[0membeddedInput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEmbeddingLayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m     \u001b[0mgruOutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfinalHiddenStates\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGRULayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membeddedInput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m     \u001b[0mgruOutsPooled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgruOutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m     \u001b[0mlinearOutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLinearLayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgruOutsPooled\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1111\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m    941\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbatch_sizes\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    942\u001b[0m             result = _VF.gru(input, hx, self._flat_weights, self.bias, self.num_layers,\n\u001b[0;32m--> 943\u001b[0;31m                              self.dropout, self.training, self.bidirectional, self.batch_first)\n\u001b[0m\u001b[1;32m    944\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    945\u001b[0m             result = _VF.gru(input, batch_sizes, hx, self._flat_weights, self.bias,\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","source":["# #save model weights\n","# torch.save(GRUTrainedModel.state_dict(), 'drive/MyDrive/NLU Project/models/modelLyricsGRU')\n","# #save the lists\n","# import pickle\n","# with open('drive/MyDrive/NLU Project/evaluation-lists/LyricsGRUTestList', 'wb') as f:\n","#   pickle.dump(epochTestAccuracyListGRU, f)\n","# with open('drive/MyDrive/NLU Project/evaluation-lists/LyricsGRUTrainList', 'wb') as f:\n","#   pickle.dump(epochTrainAccuracyListGRU, f)\n","# #run an experiment, optimizing the hyperparameters\n","# import matplotlib.pyplot as plt\n","# epochRange = np.arange(len(epochTrainAccuracyListGRU))\n","# plt.plot(epochRange, epochTrainAccuracyListGRU, label = \"Train Accuracy\")\n","# plt.plot(epochRange, epochTestAccuracyListGRU, label = \"Test Accuracy\")\n","# plt.legend()\n","# plt.show()"],"metadata":{"id":"2Cd_BnOkIkg6","executionInfo":{"status":"ok","timestamp":1652006486820,"user_tz":-60,"elapsed":202,"user":{"displayName":"Harvey South","userId":"00286034947533783714"}}},"execution_count":15,"outputs":[]}]}